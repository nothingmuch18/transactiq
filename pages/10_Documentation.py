"""Documentation â€” Architecture, sample queries, demo script."""
import streamlit as st
import sys, os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

st.set_page_config(page_title="Documentation", page_icon="ðŸ“–", layout="wide")

st.markdown("""
<div class="page-header">
    <h1>ðŸ“– Documentation</h1>
    <div class="page-subtitle">Architecture, methodology, sample queries, and demo script</div>
</div>
""", unsafe_allow_html=True)

tab1, tab2, tab3, tab4 = st.tabs(["ðŸ—ï¸ Architecture", "ðŸ“ Sample Queries", "ðŸŽ¬ Demo Script", "ðŸ“Š Methodology"])

with tab1:
    st.markdown("""
    ### System Architecture

    ```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   STREAMLIT FRONTEND                     â”‚
    â”‚  Overview â”‚ Ask AI â”‚ Explore â”‚ Insights â”‚ Risk â”‚ ...     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 AI QUERY PLANNER                         â”‚
    â”‚   Natural Language â†’ Intent Classification               â”‚
    â”‚   Entity Extraction â†’ Structured JSON Plan               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              QUERY EXECUTION ENGINE                      â”‚
    â”‚   JSON Plan â†’ Pandas Operations â†’ Results                â”‚
    â”‚   DataFrame + Chart Spec + Explanation                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                               â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 DATA LAYER (Pandas)                      â”‚
    â”‚   Auto-profiled CSV with metadata & role detection       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    ```

    ### Modules

    | Module | Purpose |
    |--------|---------|
    | `data_profiler.py` | Auto-detect schema, column roles, statistics |
    | `query_planner.py` | NL â†’ structured JSON plan (18+ intent types) |
    | `query_executor.py` | Execute plans via Pandas, return results |
    | `insight_engine.py` | Auto-generate 10 financial insights with explainability |
    | `anomaly_detector.py` | IQR, Z-score, rolling, spike, concentration, percentile |
    | `predictor.py` | Linear trend + seasonal decomposition forecasting |
    | `scenario_engine.py` | What-if simulation (value/volume/fraud/failure) |
    | `risk_analyzer.py` | HHI, volatility, risk index |
    | `comparator.py` | Side-by-side group/period comparisons |
    | `data_quality.py` | Missing, duplicates, outliers, consistency |
    | `utils.py` | Formatting, column matching, helpers |

    ### Design Decisions

    1. **No LLM dependency** â€” Keyword-based intent classification ensures zero hallucination
    2. **Plan-then-execute** â€” AI produces structured plans, backend executes them
    3. **Auto schema detection** â€” No hardcoded column names; works on any tabular dataset
    4. **Every result is explainable** â€” Shows filters, aggregation logic, and reasoning
    5. **Minimal dependencies** â€” Only streamlit, pandas, plotly, scikit-learn, numpy
    6. **Predictive module** â€” Simple statistical models with disclosed methodology
    """)

with tab2:
    st.markdown("""
    ### 25+ Sample Queries

    **Basic:**
    1. What is the total transaction value?
    2. How many transactions are there?
    3. What is the average transaction amount?
    4. Show monthly trend of transaction volume
    5. Top 10 states by transaction value

    **Analytical:**
    6. Show month-over-month growth rate
    7. Peak transaction month
    8. Distribution of transactions by category
    9. Bottom 5 states by total value
    10. Concentration analysis by state

    **Comparison:**
    11. Compare Delhi vs Maharashtra
    12. Compare P2P vs P2M transactions
    13. Weekend vs weekday volume

    **Risk & Anomaly:**
    14. What is the fraud rate?
    15. Show failed transactions by state
    16. Anomaly detection in transaction amounts

    **Filtered:**
    17. Total value of grocery transactions
    18. Show transactions above 5000
    19. Transactions between January and March
    20. Top 5 categories by average value

    **Predictive:**
    21. Forecast next month trend
    22. Predict future transaction volume
    23. Show histogram of transaction values

    **Behavioral:**
    24. Average value by age group
    25. Which bank has the most transactions?
    """)

with tab3:
    st.markdown("""
    ### Demo Script (3â€“5 Minutes)

    **Opening (30s):**
    > "This is an AI-powered data intelligence platform that analyzes UPI transaction data.
    > It converts natural language questions into structured execution plans â€” zero hallucination."

    **1. Executive Overview (45s):**
    - Navigate to Overview
    - Highlight: Total transactions, value, growth rate, risk index
    - Show trend chart and state distribution

    **2. Ask AI (90s):**
    - Query: "Top 10 states by transaction value" â†’ table + bar chart + explanation
    - Query: "Show month-over-month growth" â†’ growth rates from real data
    - Query: "Compare Delhi vs Maharashtra" â†’ side-by-side comparison
    - Emphasize: "Every number is computed from actual data."

    **3. Insights (30s):**
    - Show 10 auto-generated insights with "Why?" explanations
    - Highlight: skewness, concentration, fraud rate

    **4. Anomalies (30s):**
    - Show IQR, Z-score, and percentile results
    - Point out flagged rows with explanations

    **5. Predictions (30s):**
    - Show forecast with confidence intervals and RMSE
    - Run what-if simulation

    **Closing (15s):**
    > "Modular architecture. Zero hallucination. Works on any tabular dataset.
    > Reproducible locally in under 5 minutes."
    """)

with tab4:
    st.markdown("""
    ### Methodology

    **Query Processing Pipeline:**
    1. **Intent Classification** â€” Rule-based keyword matching across 18+ intent patterns
    2. **Entity Extraction** â€” Column names, values, date ranges, numeric thresholds
    3. **Plan Generation** â€” Structured JSON with intent, groupby, aggregation, filters, visualization
    4. **Execution** â€” Pandas operations on the raw DataFrame
    5. **Explanation** â€” Auto-generated reasoning for every result

    **Anomaly Detection Methods:**
    | Method | How It Works |
    |--------|-------------|
    | IQR | Flags values outside Q1 - 1.5Ã—IQR and Q3 + 1.5Ã—IQR |
    | Z-Score | Flags values with |z| > threshold (default 3.0) |
    | Percentile | Flags values outside 1stâ€“99th percentile |
    | Rolling Deviation | Flags daily values > 2Ïƒ from rolling mean |
    | Growth Spikes | Flags months with >50% MoM growth |
    | Concentration | Flags entities with >30% market share |

    **Forecasting Model:**
    - **Method:** Linear trend + seasonal decomposition
    - **Validation:** 80/20 train/test split with RMSE metric
    - **Confidence:** 95% confidence intervals based on residual std
    - **Disclosure:** Simple statistical model, not deep learning

    **Risk Scoring:**
    - **HHI:** Herfindahl-Hirschman Index for market concentration
    - **CV:** Coefficient of Variation for volatility
    - **Composite:** Weighted index combining concentration, failure rate, and fraud rate
    """)

st.markdown('<div class="data-footer">Data Source: UPI Transactions 2024 (Synthetic) Â· Zero Hallucination Engine</div>', unsafe_allow_html=True)
